{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game theory solver notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T20:57:15.108380Z",
     "start_time": "2017-12-16T20:57:15.102591Z"
    }
   },
   "outputs": [],
   "source": [
    "from game_theory.model import game, evolution\n",
    "from game_theory.example_payoffs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with prisoner's dilemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can construct the prisoner's dilemma game by manually constructing the payoff matrix. Similarly, game_theory.example_payoffs has a number of prebuild payoff matrices to choose from.\n",
    "\n",
    "The payoff matrix is constructed by specifying each agents payoffs by row in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T20:44:08.113299Z",
     "start_time": "2017-12-16T20:44:08.108926Z"
    }
   },
   "outputs": [],
   "source": [
    "X = [[-1, -3], [0, -2]]\n",
    "Y = [[-1, 0], [-3, -2]]\n",
    "prisoners_dilemma_constructed = [X, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T20:58:49.433147Z",
     "start_time": "2017-12-16T20:58:49.428110Z"
    }
   },
   "outputs": [],
   "source": [
    "prison = game(name=\"Prisoner's Dilemma\", payoffs=prisoners_dilemma_constructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T20:58:49.775302Z",
     "start_time": "2017-12-16T20:58:49.765313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prisoner's Dilemma\n",
       "\n",
       "              A             B\n",
       "A  [-1.0, -1.0]   [-3.0, 0.0]\n",
       "B   [0.0, -3.0]  [-2.0, -2.0]\n",
       "\n",
       "Nash Equilibrum(s) at: [[1, 1]]\n",
       "\n",
       "Social Optimal of -2.0 at: [[0, 0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with stag hunt with irrelevant alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stag example contains several irrelevant alternatives (C row and column) to the traditional stag game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T20:44:08.361931Z",
     "start_time": "2017-12-16T20:44:08.358554Z"
    }
   },
   "outputs": [],
   "source": [
    "X = [[2, 0, 0], [1, 1, 0], [-1, -1, -1]]\n",
    "Y = [[2, 1, 0], [0, 1, 0], [-1, -1, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T20:44:08.367400Z",
     "start_time": "2017-12-16T20:44:08.363751Z"
    }
   },
   "outputs": [],
   "source": [
    "stag_hunt = game(name=\"Stag Hunt\", payoffs=[X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T20:44:08.377677Z",
     "start_time": "2017-12-16T20:44:08.369193Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stag Hunt\n",
       "\n",
       "              A             B             C\n",
       "A    [2.0, 2.0]    [0.0, 1.0]    [0.0, 0.0]\n",
       "B    [1.0, 0.0]    [1.0, 1.0]    [0.0, 0.0]\n",
       "C  [-1.0, -1.0]  [-1.0, -1.0]  [-1.0, -1.0]\n",
       "\n",
       "Nash Equilibrum(s) at: [[0, 0], [1, 1]]\n",
       "\n",
       "Social Optimal of 4.0 at: [[0, 0]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stag_hunt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of iterative, non-memory game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An iterative, non-memory game involves establishing different agent types that randomly bump into each other and play their associated game for several rounds.\n",
    "\n",
    "To initialize the game, one needs to define the population of each type of agents, and the respective games that each agents play with one another. As such, one needs to define *n* 2 games where *n* is the number of agent types. In this example, each agent's payoffs remain consistent regardless of who the agent is playing against, however, each agent can have different payoffs depending on the opponents agent type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T20:44:08.869948Z",
     "start_time": "2017-12-16T20:44:08.597966Z"
    }
   },
   "outputs": [],
   "source": [
    "player_pop = {\"X\": 10, \"Y\": 5, \"Z\": 5}\n",
    "X = [[-1, -3], [0, -2]]\n",
    "Y = [[-1, -3], [-3, -2]]\n",
    "Z = [[2, 0], [1, 1]]\n",
    "games = {\"X X\": [X, X], \"X Y\": [X, Y], \"X Z\": [X, Z],\n",
    "         \"Y Y\": [Y, Y], \"Y Z\": [Y, Z], \"Z Z\": [Z, Z]}\n",
    "number_of_games = 100\n",
    "env = evolution(games=games, number_of_games=number_of_games,\n",
    "                player_pop=player_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T20:44:08.900340Z",
     "start_time": "2017-12-16T20:44:08.874420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "\n",
       "X X\n",
       "\n",
       "              A             B\n",
       "A  [-1.0, -1.0]  [-3.0, -3.0]\n",
       "B    [0.0, 0.0]  [-2.0, -2.0]\n",
       "\n",
       "Nash Equilibrum(s) at: [[1, 0]]\n",
       "\n",
       "Social Optimal of 0.0 at: [[1, 0]], \n",
       "\n",
       "X Y\n",
       "\n",
       "              A             B\n",
       "A  [-1.0, -1.0]  [-3.0, -3.0]\n",
       "B   [0.0, -3.0]  [-2.0, -2.0]\n",
       "\n",
       "Nash Equilibrum(s) at: [[1, 1]]\n",
       "\n",
       "Social Optimal of -2.0 at: [[0, 0]], \n",
       "\n",
       "X Z\n",
       "\n",
       "             A            B\n",
       "A  [-1.0, 2.0]  [-3.0, 0.0]\n",
       "B   [0.0, 1.0]  [-2.0, 1.0]\n",
       "\n",
       "Nash Equilibrum(s) at: [[1, 0], [1, 1]]\n",
       "\n",
       "Social Optimal of 1.0 at: [[0, 0], [1, 0]], \n",
       "\n",
       "Y Y\n",
       "\n",
       "              A             B\n",
       "A  [-1.0, -1.0]  [-3.0, -3.0]\n",
       "B  [-3.0, -3.0]  [-2.0, -2.0]\n",
       "\n",
       "Nash Equilibrum(s) at: [[0, 0], [1, 1]]\n",
       "\n",
       "Social Optimal of -2.0 at: [[0, 0]], \n",
       "\n",
       "Y Z\n",
       "\n",
       "             A            B\n",
       "A  [-1.0, 2.0]  [-3.0, 0.0]\n",
       "B  [-3.0, 1.0]  [-2.0, 1.0]\n",
       "\n",
       "Nash Equilibrum(s) at: [[0, 0], [1, 1]]\n",
       "\n",
       "Social Optimal of 1.0 at: [[0, 0]], \n",
       "\n",
       "Z Z\n",
       "\n",
       "            A           B\n",
       "A  [2.0, 2.0]  [0.0, 0.0]\n",
       "B  [1.0, 1.0]  [1.0, 1.0]\n",
       "\n",
       "Nash Equilibrum(s) at: [[0, 0], [1, 1]]\n",
       "\n",
       "Social Optimal of 4.0 at: [[0, 0]]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T20:44:08.915983Z",
     "start_time": "2017-12-16T20:44:08.901917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'X': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'Y': [0, 0, 0, 0, 0],\n",
       "  'Z': [0, 0, 0, 0, 0]},\n",
       " {'X': [0.0, -2.0, -2.0, 0.0, 0.0, 1.0, 0.0, 0.0, -2.0, 0.0],\n",
       "  'Y': [-2.0, -2.0, -1.0, -1.0, -2.0],\n",
       "  'Z': [2.0, 1.0, 0.0, 2.0, 1.0]},\n",
       " {'X': [0.0, -1.0, -4.0, 0.0, 0.0, 1.0, -2.0, 1.0, -2.0, 0.0],\n",
       "  'Y': [-3.0, -3.0, -3.0, 1.0, -4.0],\n",
       "  'Z': [2.0, 3.0, 0.0, 1.0, 3.0]},\n",
       " {'X': [0.0, -1.0, -3.0, -2.0, 1.0, -1.0, -2.0, 2.0, -2.0, 0.0],\n",
       "  'Y': [-5.0, -4.0, -4.0, 0.0, -6.0],\n",
       "  'Z': [2.0, 3.0, 0.0, 2.0, 5.0]},\n",
       " {'X': [1.0, -3.0, -5.0, -2.0, 2.0, -3.0, -2.0, 2.0, -2.0, 0.0],\n",
       "  'Y': [-7.0, -6.0, -2.0, -2.0, -7.0],\n",
       "  'Z': [2.0, 5.0, 1.0, 2.0, 4.0]}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.scores[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Rock, Papers, Scissors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-16T20:44:08.926818Z",
     "start_time": "2017-12-16T20:44:08.917534Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = [[0, -1, 1], [1, 0, -1], [-1, 1, 0]]\n",
    "Y = [[0, 1, -1], [-1, 0, 1], [1, -1, 0]]\n",
    "rps = game(name=\"Rock, Papers, Scissors\", payoffs=[X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock, Papers, Scissors\n",
       "\n",
       "             A            B            C\n",
       "A   [0.0, 0.0]  [-1.0, 1.0]  [1.0, -1.0]\n",
       "B  [1.0, -1.0]   [0.0, 0.0]  [-1.0, 1.0]\n",
       "C  [-1.0, 1.0]  [1.0, -1.0]   [0.0, 0.0]\n",
       "\n",
       "Nash Equilibrum(s) at: []\n",
       "\n",
       "Social Optimal of 0.0 at: [[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "\n",
    "class game():\n",
    "    \"\"\"Collection of methods to solve games in game theory.\n",
    "\n",
    "    Currently able to solve and find nash equilibriums for any two player game\n",
    "    with finite choices and deterministic strategies given player preferences\n",
    "    and actions sets (player payoffs)\n",
    "\n",
    "    Parameter:\n",
    "    ----------\n",
    "    payoffs : list of list of each player's payoffs\n",
    "        payoff matrix inputed as a list of list of each players payoffs read\n",
    "        clockwise starting from the top-right sector (quadrant)\n",
    "    name : string\n",
    "        Name of game played\n",
    "    mixed : bool\n",
    "        If true, game is solved using mixed strategies\n",
    "        If false, game is solved with only deterministic strategies\n",
    "\n",
    "    Results:\n",
    "    --------\n",
    "    self.name : string\n",
    "        Name of the game played\n",
    "    self.players : int\n",
    "        Number of players in game (#TODO expand number of players)\n",
    "    self.dim : list of int\n",
    "        List of number of choices each player has in game\n",
    "    self.payoffs : matrix of tuples (#TODO expand number of players)\n",
    "        Stores payoffs as matrix of tuples as commonly stored in game theory\n",
    "    self.nash_location : list of tuples\n",
    "        Locations of all nash equilibriums in game\n",
    "    self.nash : tuple\n",
    "        Nash Equilibrium values #TODO multi nash and mixed nash\n",
    "    self.social_opt : tuple\n",
    "        Social optimal point which is defined as the sum with equal weights\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, payoffs, name='game', mixed=False):\n",
    "        \"\"\"Initialize and run game.\"\"\"\n",
    "        self.name = name\n",
    "        self.players = 2\n",
    "        self.dim = [len(payoffs[0][0]), len(payoffs[0][1])]\n",
    "        self.payoffs = self.translate_payoffs(payoffs)\n",
    "        self.nash_location = self.find_nash(mixed)\n",
    "        self.social_optimal = self.find_social_opt()\n",
    "\n",
    "        try:\n",
    "            self.nash = self.payoffs[self.nash_location[0][0],\n",
    "                                     self.nash_location[0][1]]\n",
    "        except IndexError:\n",
    "            self.nash = None\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Print game with pandas, only 26 max choices for now.\"\"\"\n",
    "        name = [[chr(i) for i in range(ord('A'), ord('Z') + 1)][0:self.dim[0]],\n",
    "                [chr(i) for i in range(ord('A'), ord('Z') + 1)][0:self.dim[1]]]\n",
    "        df = pd.DataFrame([self.payoffs[i] for i in range(0, self.dim[0])],\n",
    "                          index=name[0], columns=name[1])\n",
    "        return(self.name + '\\n\\n' + str(df) + '\\n\\n' +\n",
    "               'Nash Equilibrum(s) at: ' + str(self.nash_location) + '\\n\\n' +\n",
    "              'Social Optimal of ' + str(self.social_optimal[0]) + ' at: ' +\n",
    "               str(self.social_optimal[1]))\n",
    "\n",
    "    def translate_payoffs(self, payoffs):\n",
    "        \"\"\"Manipulate payoffs arrays into matrix of tuples.\"\"\"\n",
    "        payoff_matrix = np.zeros((self.dim[0], self.dim[1]), dtype='f,f')\n",
    "\n",
    "        for col in range(0, self.dim[0]):\n",
    "            for row in range(0, self.dim[1]):\n",
    "                payoff_matrix[col][row][0] = payoffs[0][col][row]\n",
    "                payoff_matrix[col][row][1] = payoffs[1][col][row]\n",
    "\n",
    "        return(payoff_matrix)\n",
    "\n",
    "    def find_nash(self, mixed):\n",
    "        \"\"\"Solve for the nash equilibrium coordinates.\n",
    "\n",
    "        Currently information is saved as a matrix of tuples. Unclear if that\n",
    "        will remain if multiagents are added.\n",
    "        #TODO mixed strategies\n",
    "        #TODO multiagents\n",
    "        \"\"\"\n",
    "        if not mixed:\n",
    "            nash = np.zeros((self.dim[0], self.dim[1]), dtype='f,f')\n",
    "\n",
    "            player_1_choices = []\n",
    "            for row in range(0, self.dim[1]):\n",
    "                payoffs_per_column = [payoff[0] for payoff in\n",
    "                                      [column[row] for column in self.payoffs]]\n",
    "                player_1_choices.append(\n",
    "                    np.argwhere(\n",
    "                        payoffs_per_column == np.amax(payoffs_per_column)))\n",
    "\n",
    "            for row in range(0, self.dim[1]):\n",
    "                if len(player_1_choices[row].flatten()) == 1:\n",
    "                    nash[player_1_choices[row].flatten()[0]][row][0] = 1\n",
    "                else:\n",
    "                    for j in range(0, len(player_1_choices[row].flatten())):\n",
    "                        nash[player_1_choices[row].flatten()[j]][row][0] = 1\n",
    "\n",
    "            player_2_choices = []\n",
    "            for col in range(0, self.dim[0]):\n",
    "                payoffs_per_row = [row[1] for row in self.payoffs[col]]\n",
    "                player_2_choices.append(\n",
    "                    np.argwhere(payoffs_per_row == np.amax(payoffs_per_row)))\n",
    "\n",
    "            for col in range(0, self.dim[0]):\n",
    "                if len(player_2_choices[col].flatten()) == 1:\n",
    "                    nash[col][player_2_choices[col].flatten()[0]][1] = 1\n",
    "                else:\n",
    "                    for j in range(0, len(player_2_choices[col].flatten())):\n",
    "                        nash[col][player_2_choices[col].flatten()[j]][1] = 1\n",
    "        else:\n",
    "            print(\"TODO\")\n",
    "\n",
    "        coords = []\n",
    "        for col in range(0, self.dim[0]):\n",
    "            for row in range(0, self.dim[1]):\n",
    "                if nash[col][row][0] == 1 and nash[col][row][1] == 1:\n",
    "                    coords.append([col, row])\n",
    "\n",
    "        return(coords)\n",
    "\n",
    "    def find_social_opt(self):\n",
    "        \"\"\"Find social optimal and its location\"\"\"\n",
    "        social_optimal = sum(self.payoffs[0][0])\n",
    "        social_optimal_loc = []\n",
    "\n",
    "        for col in range(0, self.dim[0]):\n",
    "            for row in range(0, self.dim[1]):\n",
    "                if social_optimal < sum(self.payoffs[col][row]):\n",
    "                    social_optimal = sum(self.payoffs[col][row])\n",
    "                    social_optimal_loc = [[col, row]]\n",
    "                elif social_optimal == sum(self.payoffs[col][row]):\n",
    "                    social_optimal_loc.append([col, row])\n",
    "\n",
    "        return(social_optimal, social_optimal_loc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock, Papers, Scissors\n",
       "\n",
       "             A            B            C\n",
       "A   [0.0, 0.0]  [-1.0, 1.0]  [1.0, -1.0]\n",
       "B  [1.0, -1.0]   [0.0, 0.0]  [-1.0, 1.0]\n",
       "C  [-1.0, 1.0]  [1.0, -1.0]   [0.0, 0.0]\n",
       "\n",
       "Nash Equilibrum(s) at: []\n",
       "\n",
       "Social Optimal of 0.0 at: [[0, 0], [0, 1], [0, 2], [1, 0], [1, 1], [1, 2], [2, 0], [2, 1], [2, 2]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "for col in range(0, 3):\n",
    "    for row in range(0, 3):\n",
    "        x.append(rps.payoffs[col][row][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.mat(x).reshape((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 3]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
