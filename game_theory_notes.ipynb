{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game theory solver notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T21:33:50.286792Z",
     "start_time": "2017-11-30T21:33:49.704794Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "class game():\n",
    "    \"\"\"\n",
    "    Method for individual game which finds nash equilibrium(s) given player preferences\n",
    "    and actions sets (player payoffs)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, payoffs, name='game'):\n",
    "        self.name = name\n",
    "        self.players = 2\n",
    "        self.dim = [len(payoffs[0]), len(payoffs[0][1])]\n",
    "        self.payoffs = self.translate_payoffs(payoffs)\n",
    "        self.nash = self.find_nash()\n",
    "        \n",
    "        \n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Pandas looks nicer when presenting, unclear if its too costly to create a DataFrame.\n",
    "        Only 26 max choices for now.\n",
    "        \"\"\"\n",
    "        names = [[chr(i) for i in range(ord('A'), ord('Z')+1)][0:self.dim[0]],\n",
    "                 [chr(i) for i in range(ord('A'), ord('Z')+1)][0:self.dim[1]]]\n",
    "        df = pd.DataFrame([self.payoffs[i] for i in range(0, self.dim[0])],\n",
    "                          index=names[0], columns=names[1])\n",
    "        return(self.name + '\\n\\n' + str(df) + '\\n\\n' + \"Nash Equilibrum(s) at:\"+ str(self.nash))\n",
    "    \n",
    "    def translate_payoffs(self, payoffs):\n",
    "        \"\"\"\n",
    "        Manipulates payoffs arrays into matrix of tuples\n",
    "        \"\"\"\n",
    "        payoff_matrix = np.zeros((self.dim[0], self.dim[1]),dtype='int,int')\n",
    "        \n",
    "        for i in range(0, self.dim[0]):\n",
    "            for j in range(0, self.dim[1]):\n",
    "                payoff_matrix[i][j][0] = payoffs[0][i][j]\n",
    "                payoff_matrix[i][j][1] = payoffs[1][i][j]\n",
    "                \n",
    "        return(payoff_matrix)\n",
    "\n",
    "        \n",
    "    def find_nash(self):\n",
    "        \"\"\"\n",
    "        Solves for the nash equilibrium coordinates\n",
    "        \"\"\"\n",
    "        nash = np.zeros((self.dim[0], self.dim[1]),dtype='int,int')\n",
    "\n",
    "        player_1_choices = []\n",
    "        for i in range(0, self.dim[1]):\n",
    "            payoffs_per_column = [payoff[0] for payoff in [column[i] for column in self.payoffs]]\n",
    "            player_1_choices.append(np.argwhere(payoffs_per_column == np.amax(payoffs_per_column)))\n",
    "\n",
    "        for i in range(0, self.dim[1]):\n",
    "            if len(player_1_choices[i].flatten()) == 1:\n",
    "                nash[player_1_choices[i].flatten()[0]][i][0] = 1\n",
    "            else:\n",
    "                for j in range(0, len(player_1_choices[i].flatten())):\n",
    "                    nash[player_1_choices[i].flatten()[j]][i][0] = 1\n",
    "\n",
    "\n",
    "        player_2_choices = []\n",
    "        for i in range(0, self.dim[0]):\n",
    "            payoffs_per_row = [row[1] for row in self.payoffs[i]]\n",
    "            player_2_choices.append(np.argwhere(payoffs_per_row == np.amax(payoffs_per_row)))\n",
    "\n",
    "        for i in range(0, self.dim[0]):\n",
    "            if len(player_2_choices[i].flatten()) == 1:\n",
    "                nash[i][player_2_choices[i].flatten()[0]][1] = 1\n",
    "            else:\n",
    "                for j in range(0, len(player_2_choices[i].flatten())):\n",
    "                    nash[i][player_2_choices[i].flatten()[j]][1] = 1\n",
    "                    \n",
    "        coords = []\n",
    "        for i in range(0, self.dim[0]):\n",
    "            for j in range(0, self.dim[1]):\n",
    "                if nash[i][j][0] == 1 and nash[i][j][1] == 1:\n",
    "                    coords.append([i, j])\n",
    "\n",
    "        return(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with stag hunt with irrelevant alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T21:33:50.302292Z",
     "start_time": "2017-11-30T21:33:50.288793Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [[2, 0], [1, 1], [0, 0]]\n",
    "Y = [[2, 1], [0, 1], [0,0 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T21:33:50.325293Z",
     "start_time": "2017-11-30T21:33:50.305792Z"
    }
   },
   "outputs": [],
   "source": [
    "stag_hunt = game(name=\"Stag Hunt\", payoffs=[X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T21:33:50.363793Z",
     "start_time": "2017-11-30T21:33:50.327792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stag_hunt.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T21:33:50.408292Z",
     "start_time": "2017-11-30T21:33:50.365793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stag Hunt\n",
       "\n",
       "        A       B\n",
       "A  [2, 2]  [0, 1]\n",
       "B  [1, 0]  [1, 1]\n",
       "C  [0, 0]  [0, 0]\n",
       "\n",
       "Nash Equilibrum(s) at:[[0, 0], [1, 1]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stag_hunt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with prisoner's dilemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T21:33:50.429292Z",
     "start_time": "2017-11-30T21:33:50.411294Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [[-1, -3], [0, -2]]\n",
    "Y = [[-1, -3], [-3, -2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T21:33:50.450794Z",
     "start_time": "2017-11-30T21:33:50.432792Z"
    }
   },
   "outputs": [],
   "source": [
    "prison = game(name=\"Prisoner's Dilemma\", payoffs=[X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-30T21:33:50.497295Z",
     "start_time": "2017-11-30T21:33:50.455293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prisoner's Dilemma\n",
       "\n",
       "          A         B\n",
       "A  [-1, -1]  [-3, -3]\n",
       "B   [0, -3]  [-2, -2]\n",
       "\n",
       "Nash Equilibrum(s) at:[[1, 1]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
